{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dI-u-xCg8M5Z"
      },
      "source": [
        "\n",
        "\n",
        "# Using CNNs to analyze oculomotor timecourse data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before running this code, make sure to select a fast runtime (either your own local runtime or one provided by Colab), as the model fitting procedure and SHAP analysis takes quite some time on the CPU alone.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "LXgnnJqpu3I0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load in necessary libraries"
      ],
      "metadata": {
        "id": "BVYiAH0HIaMg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jq6Gzp5X8M5Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "274a6041-bb07-44b1-8526-cdd9aa03bcdf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting shap\n",
            "  Downloading shap-0.47.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from shap) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from shap) (1.15.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from shap) (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from shap) (2.2.2)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.11/dist-packages (from shap) (4.67.1)\n",
            "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.11/dist-packages (from shap) (25.0)\n",
            "Collecting slicer==0.0.8 (from shap)\n",
            "  Downloading slicer-0.0.8-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: numba>=0.54 in /usr/local/lib/python3.11/dist-packages (from shap) (0.61.2)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from shap) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from shap) (4.13.2)\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.54->shap) (0.44.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->shap) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->shap) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->shap) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->shap) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->shap) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->shap) (1.17.0)\n",
            "Downloading shap-0.47.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading slicer-0.0.8-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: slicer, shap\n",
            "Successfully installed shap-0.47.2 slicer-0.0.8\n"
          ]
        }
      ],
      "source": [
        "# libraries related to neural network\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# libraries related to input/output arrays\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "#libraries related to importing data into script\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "from google.colab import files\n",
        "\n",
        "#libraries related to graphing NN results\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "#SHAP values\n",
        "!pip install shap\n",
        "import shap"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pre-define values based on your data"
      ],
      "metadata": {
        "id": "L4S8-NjmrvIe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "desiredLabel = \"targetLocation\" #what is the column name of the values you are trying to predict?\n",
        "inputFeatures = 2 #how many features does your input data have?\n",
        "outputClasses = 6 #how many unique values could your predicted label have?\n",
        "removeNAs = False #Are there NAs in your data/labels (e.g., a distractor not appearing on some trials), and should they be removed?\n",
        "numericallyEncode = True #Do your labels need to be numerically encoded?"
      ],
      "metadata": {
        "id": "LQKJ6GwlrvZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load in data\n",
        "Your data should be in the form of a .csv file for each feature, with trials as rows and samples as columns. Your conditions file should be in the form of a .csv file, with trials as rows.\n",
        "\n",
        "Before running this code, click the file icon on the left sidebar, click the \"Upload to session storage\" icon (the page icon with the upwards arrow) and upload your feature .csv files. You can write code to do this, but the GUI-based method is much faster.\n"
      ],
      "metadata": {
        "id": "dmAwA_TSQ2XP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#upload = files.upload() #The GUI is actually much faster at this\n",
        "# load in data\n",
        "feature1 = pd.read_csv('CMBG_BRM_Section2_XPos.csv')\n",
        "feature2 = pd.read_csv('CMBG_BRM_Section2_YPos.csv')\n",
        "#repeat above for as many features as you are uploading\n",
        "\n",
        "conditions = pd.read_csv('CMBG_BRM_Section2_Conditions.csv')\n",
        "data = np.stack((feature1, feature2), axis=1) #add more features if needed\n",
        "print(data.shape)"
      ],
      "metadata": {
        "id": "RNOrAMS-SglC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "868c707b-3832-4b6b-ca2e-1a94536f09b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(23280, 2, 601)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove row labels from data if necessary\n",
        "data = data[:,:,1:]"
      ],
      "metadata": {
        "id": "Smp2VEHlTp5I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.shape)"
      ],
      "metadata": {
        "id": "GZhyzIGzVKM_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cab9f5c1-eb4f-4dc9-c0a1-6c7d79c7686e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(23280, 2, 600)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Extract desired labels from conditions datafile"
      ],
      "metadata": {
        "id": "A1YKRS0cv8oi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#remove NA values if necessary (e.g., if search object is absent on some trials)\n",
        "if removeNAs == True:\n",
        "  data = data[conditions[desiredLabel].isna()==False, :, :]\n",
        "  conditions = conditions[conditions[desiredLabel].isna()==False]\n",
        "\n",
        "#extract label information from conditions file - this will serve as the comparison during supervised learning\n",
        "labels = conditions[desiredLabel]\n",
        "\n",
        "#numerical encoding of labels -- The actual method of encoding can change based on your data.\n",
        "#the example encoding is what we used for our reported analyses.\n",
        "if numericallyEncode == True:\n",
        "  labels = labels.map({0:0, 60:1, 120:2, 180:3, 240:4, 300:5})"
      ],
      "metadata": {
        "id": "7H3FVtj4v3U9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(labels.head())"
      ],
      "metadata": {
        "id": "NRZucDRQUgY7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35a2c306-5f94-4782-8d7e-37c93f8b2829"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(23280, 6)\n",
            "   Unnamed: 0  targetLocation  distractorPresence  distractorLocation  \\\n",
            "0           1             180               False                   4   \n",
            "1           2             300                True                 120   \n",
            "2           3             120               False                 120   \n",
            "3           4             120                True                 180   \n",
            "4           5             300               False                 180   \n",
            "\n",
            "   subjNum studyOrigin  \n",
            "0      110          RR  \n",
            "1      110          RR  \n",
            "2      110          RR  \n",
            "3      110          RR  \n",
            "4      110          RR  \n",
            "0    3\n",
            "1    5\n",
            "2    2\n",
            "3    2\n",
            "4    5\n",
            "Name: targetLocation, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training-validation split (66% training, 33% validation)"
      ],
      "metadata": {
        "id": "c-NfFNwuxivI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = np.zeros(shape = ( (int((2/3)*np.shape(data)[0])), np.shape(data)[1], np.shape(data)[2] ))\n",
        "test_data = np.zeros(shape = ( (int((1/3)*np.shape(data)[0])), np.shape(data)[1], np.shape(data)[2] ))\n",
        "\n",
        "training_labels = []\n",
        "test_labels = []\n",
        "\n",
        "trainCounter = 0\n",
        "testCounter = 0\n",
        "\n",
        "for i in range(0, len(data)):\n",
        "  if i % 3 == 0: #every third trial, add data and label to validation set\n",
        "    test_data[testCounter, :, : ] = data[i, :, :]\n",
        "    test_labels.append(labels.iloc[i])\n",
        "    testCounter += 1\n",
        "  else: #otherwise, add data and label to training set\n",
        "    training_data[trainCounter, :, : ] = data[i, :, :]\n",
        "    training_labels.append(labels.iloc[i])\n",
        "    trainCounter += 1\n",
        "\n",
        "training_labels = pd.Series(training_labels)\n",
        "test_labels = pd.Series(test_labels)\n"
      ],
      "metadata": {
        "id": "mmk-AIP3xqOF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pre-process data"
      ],
      "metadata": {
        "id": "m9mb9MoATOEk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#transform numpy data to tensor\n",
        "training_data = torch.from_numpy(training_data)\n",
        "test_data = torch.from_numpy(test_data)\n",
        "\n",
        "#change to float type - more easily handled by training + test loops\n",
        "training_data = training_data.float()\n",
        "test_data = test_data.float()"
      ],
      "metadata": {
        "id": "pGX7ZkgOUhC7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Check dimensions of test data and labels"
      ],
      "metadata": {
        "id": "edIcRkTowJDm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_data.shape)\n",
        "#trials, features, samples\n",
        "\n",
        "print(test_labels.shape)\n",
        "# 1-dimensional tensor of identical length to rows of test data"
      ],
      "metadata": {
        "id": "BBQ8GhxzwO3S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b4443f6-3e8c-4df3-8942-40705c575ce5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([7760, 2, 600])\n",
            "(7760,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Determine size of flattened output passed to first linear transform -- different based on the length of your trial and number of features"
      ],
      "metadata": {
        "id": "Ph5-Bt0mEJx-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sizeChecker = nn.Sequential( #the same layers as the first portion of the CNN, just to see what that layer's output size will be\n",
        "        nn.Conv1d(in_channels = inputFeatures, out_channels = 64, kernel_size = 3),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.25),\n",
        "        nn.MaxPool1d(kernel_size=5),\n",
        "        nn.Flatten()\n",
        "        )\n",
        "tmp = sizeChecker(test_data)\n",
        "flattenOutput = tmp.shape[1]\n",
        "print(flattenOutput)"
      ],
      "metadata": {
        "id": "f-1TWELREcce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d990c429-b225-4923-abf7-024630764b71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7616\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialize the neural network\n"
      ],
      "metadata": {
        "id": "yN8rLWuNkoCq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        #Flattening layer (gets called after Sequential convolution layer)\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "        #Sequential layer containing convolution and subsequent regularization methods\n",
        "        self.cnnL1 = nn.Sequential(\n",
        "        nn.Conv1d(in_channels = inputFeatures, out_channels = 64, kernel_size = 3),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.25),\n",
        "        nn.MaxPool1d(kernel_size=5),\n",
        "        )\n",
        "\n",
        "        #Linear transforms\n",
        "        self.lin = nn.Linear(in_features = flattenOutput, out_features = 64)\n",
        "        self.lin2 = nn.Linear(in_features = 64, out_features = 32)\n",
        "        self.lin3 = nn.Linear(in_features = 32, out_features = outputClasses) #Output is X number of logits, to be used as the CNN's predictions with loss function\n",
        "\n",
        "    def forward(self, x):\n",
        "        #apply convolution\n",
        "        conv = self.cnnL1(x)\n",
        "\n",
        "        #rearrage resulting array for proper order during flattening\n",
        "        permuted = conv.permute(0,2,1)\n",
        "\n",
        "        #flatten array into one-dimensional tensor\n",
        "        flattened = self.flatten(permuted)\n",
        "\n",
        "        #linear transforms, with logits as output\n",
        "        linear = self.lin(flattened)\n",
        "        linear2 = self.lin2(linear)\n",
        "        logits = self.lin3(linear2)\n",
        "        return logits\n",
        "\n",
        "model = NeuralNetwork()"
      ],
      "metadata": {
        "id": "ACZkKG4W8ljE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialize Early Stopping class"
      ],
      "metadata": {
        "id": "VMZ14NwJn5a6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#EarlyStopping class used in pytorchtools library\n",
        "#source: https://github.com/Bjarten/early-stopping-pytorch/blob/master/pytorchtools.py\n",
        "class EarlyStopping:\n",
        "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
        "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pth', trace_func=print):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): How long to wait after last time validation loss improved.\n",
        "                            Default: 7\n",
        "            verbose (bool): If True, prints a message for each validation loss improvement.\n",
        "                            Default: False\n",
        "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
        "                            Default: 0\n",
        "            path (str): Path for the checkpoint to be saved to.\n",
        "                            Default: 'checkpoint.pt'\n",
        "            trace_func (function): trace print function.\n",
        "                            Default: print\n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.inf\n",
        "        self.delta = delta\n",
        "        self.path = path\n",
        "        self.trace_func = trace_func\n",
        "    def __call__(self, val_loss, model):\n",
        "\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        '''Saves model when validation loss decrease.'''\n",
        "        if self.verbose:\n",
        "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "        torch.save(model.state_dict(), self.path)\n",
        "        self.val_loss_min = val_loss"
      ],
      "metadata": {
        "id": "h4-kQmcMn5jg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define a Custom Dataset object that stores the samples and the labels together for each trial"
      ],
      "metadata": {
        "id": "8QBhH8cutUmr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, labelsObject, dataObject, transform=None, target_transform=None):\n",
        "        self.labels = labelsObject\n",
        "        self.dataframe = dataObject\n",
        "        self.transform = transform #in case data needs to be transformed to a different type\n",
        "        self.target_transform = target_transform #in case labels need to be transformed to a different type\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        data = self.dataframe[idx]\n",
        "        label = self.labels.iloc[idx]\n",
        "        if self.transform:\n",
        "            data = self.transform(data)\n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(label)\n",
        "        return data, label"
      ],
      "metadata": {
        "id": "xJXrHXi_D1Yj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create the CustomDatasets for training and validation data"
      ],
      "metadata": {
        "id": "3XSb2czvtzbP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = CustomDataset(labelsObject = training_labels, dataObject = training_data)\n",
        "test = CustomDataset(labelsObject = test_labels, dataObject = test_data)"
      ],
      "metadata": {
        "id": "xDWngfZatzlY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create DataLoader objects containing the training and test data/labels\n",
        "After our data and labels have been stored in our Custom Dataset objects, we need to place these objects into an object called a Dataloader. Dataloaders are PyTorch objects designed to divide input files into a series of minibatches and feed them into a CNN. This batching process allows the network to update its parameters more frequently than if it was fit to all of the data at once. The size of each minibatch, controlled by ``batch_size``, is the number of data samples propagated through the CNN before the parameters are updated. In the current study, we chose a minibatch size of 64 samples."
      ],
      "metadata": {
        "id": "gMMqp0N4UzoL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "train_dataloader = DataLoader(train, batch_size=batch_size, drop_last=False)\n",
        "test_dataloader = DataLoader(test, batch_size=batch_size, drop_last=False)"
      ],
      "metadata": {
        "id": "lnJkTN0HFjEU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wiT4f2wY8M5a"
      },
      "source": [
        "## Hyperparameters & Optimizer\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vxegQ-898M5a"
      },
      "outputs": [],
      "source": [
        "#Hyperparameters\n",
        "learning_rate = 1e-3\n",
        "epochs = 2500 #arbitrary large number to give time for early stopping to occur\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "#Adam optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJGLYx-r8M5b"
      },
      "source": [
        "\n",
        "## Full Implementation\n",
        "Here, we create our respective loops for the training/validation process with one function for training and one function for validation. The validation function also stores the trial-level accuracies of the CNN, which will be used to graph the CNN's classification accuracy later on.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eshSqRXG8M5c"
      },
      "outputs": [],
      "source": [
        "def train_model(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train() #set the model to training mode - important for batch normalization and dropout layers\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "\n",
        "        #compute prediction and loss\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        #backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        #print current loss every 20 batches\n",
        "        if batch % 20 == 0:\n",
        "            loss, current = loss.item(), batch * batch_size + len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "\n",
        "def test_model(dataloader, model, loss_fn, trialLevelDF, epNum = 0, earlyStop=\"none\", lossChecker = \"none\", mode = \"loss\"):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.eval() #set the model to evaluation mode - important for batch normalization and dropout layers\n",
        "\n",
        "    num_batches = len(dataloader)\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    #evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
        "    with torch.no_grad():\n",
        "      batchCount = 0\n",
        "      for X, y in dataloader:\n",
        "          pred = model(X) #apply model to batch\n",
        "          predSize = len(pred)\n",
        "          for p in (range(predSize)): #iterate through current batch to get trial-level accuracies\n",
        "\n",
        "              #determine whether there was a correct or incorrect prediction on the current dataframe\n",
        "              trialAcc = (pred[p].argmax().item() == y[p].item())\n",
        "\n",
        "              #save trial-level accuracy to initialized dataframe\n",
        "              trialLevelDF.iloc[(batch_size*batchCount)+p,epNum] = trialAcc\n",
        "\n",
        "          #update loss and accuracy metrics for reporting\n",
        "          test_loss += loss_fn(pred, y).item()\n",
        "          correct += (pred.argmax(1) == y).type(torch.float).sum().item() #same calculation as above, but performed for entire batch at once\n",
        "          batchCount+=1\n",
        "\n",
        "    #compute overall loss and accuracy\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "\n",
        "    #if we want to save the CNN's lowest loss value, record that minimum loss and the epoch where it occurred\n",
        "    if lossChecker != \"none\" and test_loss < lossChecker[0]:\n",
        "      lossChecker[0] = test_loss\n",
        "      lossChecker[1] = epNum\n",
        "\n",
        "    #if we want to implement early stopping, apply early stopping\n",
        "    if earlyStop != \"none\":\n",
        "      earlyStop(test_loss, model)\n",
        "\n",
        "    #print the relevant performance metrics -- loss or accuracy\n",
        "    if mode == \"loss\":\n",
        "      print(f\"Epoch {epNum+1} complete! \\n Current loss: {test_loss:>8f}    Lowest loss: {lossChecker[0]:>8f} \\n\")\n",
        "    elif mode == \"accuracy\":\n",
        "      print(f\"Accuracy: {(100*correct):>8f}% \\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mScO9OrS8M5c"
      },
      "source": [
        "# Implement training and test procedures\n",
        "\n",
        "Here, we initalize a dataframe to store the trial-level validation accuracies and implement the training and validation functions we created earlier. We also save the trial-level accuracies as a .csv file to store the NN's current performance (as the fitting process is stochastic).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lz5_Cozo8M5c"
      },
      "outputs": [],
      "source": [
        "#for storing CNN validation accuracy in each epoch\n",
        "performanceSummary = pd.DataFrame(index=range(len(test_dataloader.dataset)), columns = range(epochs))\n",
        "\n",
        "#early stopping object\n",
        "early_stopping = EarlyStopping(patience=10, verbose=True)\n",
        "\n",
        "#for storing minimum loss value and epoch where it occurred\n",
        "lossCheck = [np.inf, 0]\n",
        "\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "\n",
        "    #training\n",
        "    train_model(train_dataloader, model, loss_fn, optimizer)\n",
        "\n",
        "    #validation\n",
        "    test_model(test_dataloader, model, loss_fn, performanceSummary,\n",
        "               epNum = t, earlyStop = early_stopping, lossChecker=lossCheck, mode = \"loss\")\n",
        "\n",
        "    #check early stopping criteria\n",
        "    if early_stopping.early_stop:\n",
        "      print(f\"Early stopping @ epoch {t+1}\")\n",
        "      break\n",
        "\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Quick summary of model results\n",
        "Once our CNN has been fit to the data, we can take a quick look at its accuracy in predicting target location from eye position using the trial level accuracies. Here, we graph the accuracy across all run epochs, and identify the accuracy that occurred when the network demonstrated minimum loss. This accuracy value is the one we use as a metric of model performance. The associated parameter weights that gave rise to this performance have been saved as `checkpoint.pth`, and"
      ],
      "metadata": {
        "id": "GMhTBfUHjs1M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "bestEpoch = lossCheck[1]\n",
        "#bestEpoch = 25\n",
        "performanceSummary = performanceSummary.iloc[:,0:t+1] #in case early stopping happens\n",
        "epAcc = (100*(performanceSummary.sum() / len(test_dataloader.dataset)))\n",
        "plt.plot(range(1,t+2), epAcc)\n",
        "plt.arrow(x = bestEpoch+1, y = epAcc[bestEpoch] - 5, dx = 0, dy = 3, width = .2)\n",
        "plt.text(x = bestEpoch-10, y = epAcc[bestEpoch] - 12, s = f\"Accuracy from epoch {bestEpoch+1} with \\n the lowest loss -- \\n we use this in analysis!\")\n",
        "plt.text(x = bestEpoch-10, y = epAcc[bestEpoch] - 25, s = \"Note: Overfitting may have \\n happened in later epochs, \\n causing a severe accuracy \\n decrease\")\n",
        "print(performanceSummary)"
      ],
      "metadata": {
        "id": "9TFvZMZk1p5o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Download trial level accuracy as .csv file through Google Drive"
      ],
      "metadata": {
        "id": "pv_4aFEBFmPQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "trialLevelAcc.to_csv('drive/My Drive/.csv')\n",
        "files.download('drive/My Drive/.csv')"
      ],
      "metadata": {
        "id": "x9yZ_J6Rmcpy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save model parameter weights locally and download to computer"
      ],
      "metadata": {
        "id": "7_Yr1zQZrWeo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "torch.save(model.state_dict(), \".pth\") #.pth file is type used for storing parameter weights\n",
        "files.download(\".pth\")"
      ],
      "metadata": {
        "id": "dYILF6j2We5A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#IF NEEDED, upload weights from previous model for SHAP value analysis"
      ],
      "metadata": {
        "id": "fyVaKQACB8a3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#to upload weights from previous model\n",
        "#modelWeights = torch.load(\".pth\") #change to pth file of corresponding model\n",
        "#model.load_state_dict(modelWeights)"
      ],
      "metadata": {
        "id": "WzdzbEXAa9WQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Calculate SHAP values for each trial of validation set (this takes a substantial amount of time to run)"
      ],
      "metadata": {
        "id": "JAjSseyvBIWS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trialLevelSHAP = pd.DataFrame(index=range(len(test_dataloader.dataset)), columns = range(len(test_dataloader.dataset[0][0][0])))\n",
        "print(trialLevelSHAP.shape)\n",
        "\n",
        "shapBatch = test_dataloader.dataset[0:100] #first 100 trials used for explanation model\n",
        "explainer = shap.DeepExplainer(model, shapBatch[0])\n",
        "\n",
        "loopDur = len(test_dataloader.dataset)\n",
        "for s in range(loopDur):\n",
        "\n",
        "  #calculate SHAP values relative to explainer set\n",
        "  shap_values = explainer.shap_values(test_dataloader.dataset[s:s+1][0])\n",
        "\n",
        "  #compute global feature importance by taking absolute value\n",
        "  abs_shap_values = np.abs(shap_values)\n",
        "\n",
        "  #average across classes and features to get one global feature importance value per sample\n",
        "  SHAP = abs_shap_values.mean(axis=(0,1,3))\n",
        "\n",
        "  #save trial-level accuracy to initialized dataframe\n",
        "  trialLevelSHAP.iloc[s,:] = SHAP\n",
        "  if s % 100 ==0:\n",
        "    print(s)\n",
        "\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "id": "WEkHk05hDwAN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Download SHAP values as .csv file"
      ],
      "metadata": {
        "id": "LK2cKbmYJiji"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trialLevelSHAP = pd.DataFrame(trialLevelSHAP)\n",
        "trialLevelSHAP.to_csv('drive/My Drive/.csv')\n",
        "files.download('drive/My Drive/.csv')"
      ],
      "metadata": {
        "id": "Hu5KpAP6jBcc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Graphing heatmap of results for last trial as a quick check\n",
        "df = pd.DataFrame({\"SHAP values for each sample in timecourse\": abs_shap_values.mean(axis=(0,1,3))},\n",
        "                  index=range(len(shap_values[0][0])))\n",
        "g = sns.heatmap(df, fmt=\"g\", cmap='viridis')\n",
        "g.set_yticks(range(0,600,50))\n",
        "g.set_yticklabels(range(0,600,50))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YbdUOf8I3VXX"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V6E1"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}